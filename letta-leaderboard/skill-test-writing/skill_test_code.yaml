name: skill-test-writing
description: Evaluate if agent can write high-quality test cases for skills
dataset: data/dataset.jsonl

target:
  kind: letta_code
  base_url: https://api.letta.com/
  working_dir: output
  sandbox: false
  skills_dir: .skills
  timeout: 600
  max_retries: 1
  model_handles:
    # Anthropic
    - anthropic/claude-opus-4-5-20251101
    - anthropic/claude-sonnet-4-5-20250929
    - anthropic/claude-haiku-4-5-20251001
    # OpenAI (only GPT-5.x models work)
    - openai/gpt-5.2-2025-12-11
    - openai/gpt-5.1-codex
    - openai/gpt-5.1-codex-mini
    # Google (use shorthand, not google/ prefix)
    - gemini-3-flash
    # gemini-3-pro not available in letta CLI
    # Other providers (via openrouter)
    - openrouter/z-ai/glm-4.6
    - openrouter/minimax/minimax-m2
    - openrouter/deepseek/deepseek-r1
    - openrouter/deepseek/deepseek-chat
    - openrouter/meta-llama/llama-3.3-70b-instruct
    - openrouter/qwen/qwen-2.5-coder-32b-instruct
    - openrouter/mistralai/mistral-large-2411

graders:
  test_quality:
    kind: model_judge
    display_name: "test quality score"
    model: claude-sonnet-4-5-20250929
    temperature: 0.0
    provider: anthropic
    prompt_path: judge_prompt.md
    extractor: last_assistant

gate:
  kind: simple
  metric_key: test_quality
  aggregation: avg_score
  op: gte
  value: 0.6
