{"sample_id": "handoff-001", "input": "Session transcript:\n\nAlice: hey, so I've been thinking about where to put the sidecar environments. Right now they're scattered across a few different repos and it's getting messy.\nBob: Yeah I noticed that too. What about putting them under letta-leaderboard? That way they're close to the eval infrastructure.\nAlice: Makes sense. We could do letta-leaderboard/sidecar-envs as the root, and then each env gets its own subfolder.\nBob: I like that. Let's go with that structure.\nAlice: Cool. Other thing - I've been updating the smoke suite. We were pointing at localhost before, but now that the cloud API is stable we should probably just default everything to https://api.letta.com/\nBob: Oh right, yeah that makes way more sense for CI. Did you already update the yaml?\nAlice: Yeah I pushed a change to suite_smoke.yaml. Also threw in a couple more baseline models while I was at it - we had too few for meaningful comparison.\nBob: Nice. Where's the suite file now?\nAlice: letta-leaderboard/sidecar-envs/user-model-maintenance/suite_smoke.yaml. And the dataset is at letta-leaderboard/sidecar-envs/user-model-maintenance/data/dataset_full.jsonl\nBob: Got it. Have you actually run the full suite end to end yet?\nAlice: Not yet, that's still on my list. Need to do a full run and get the scores recorded somewhere.\nBob: We should also bump up the dataset size. How many samples are in it right now?\nAlice: Like 8 I think? We should probably get it to at least 20 for any kind of statistical significance.\nBob: Agreed. Oh hey totally unrelated but did you see the email about lunch? They're bringing in tacos on Friday.\nAlice: Oh nice, I saw that. Also apparently they restocked the snack shelf with those fancy chips everyone was asking about.\nBob: lol okay well I'll probably come in for that alone. Anyway, let me know when you kick off the full suite run.\nAlice: Will do.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"We set the sidecar envs root under letta-leaderboard/sidecar-envs, updated suites to use the cloud base URL, and expanded the smoke baselines.\",\n  \"decisions\": [\n    \"Use letta-leaderboard/sidecar-envs as the collection root\",\n    \"Default suite base_url to https://api.letta.com/\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Run full suite and record scores\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Expand full dataset to ~20 samples\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [],\n  \"next_steps\": [\n    \"Run the full suite\",\n    \"Grow dataset size\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"suite\",\n      \"path\": \"letta-leaderboard/sidecar-envs/user-model-maintenance/suite_smoke.yaml\",\n      \"description\": \"Smoke suite\"\n    },\n    {\n      \"type\": \"dataset\",\n      \"path\": \"letta-leaderboard/sidecar-envs/user-model-maintenance/data/dataset_full.jsonl\",\n      \"description\": \"Full dataset\"\n    }\n  ],\n  \"discarded\": [\n    \"Lunch plans\",\n    \"Office snacks chat\"\n  ]\n}"}
{"sample_id": "handoff-002", "input": "Session transcript:\n\nMaya: So I've been looking at the landing page mockups. I think we should go with the Garnet palette - the warm tones feel more inviting than the Slate option.\nJake: Let me pull up the Figma. You're talking about landing-v3 right?\nMaya: Yeah, figma://project/landing-v3. Compare slides 3 and 4.\nJake: Oh yeah the Garnet definitely pops more. What about the typography though? I feel like the default system font looks a bit bland next to those colors.\nMaya: I was playing around with Söhne and it pairs really well with the warm palette. Has that nice geometric feel without being too sterile.\nJake: Söhne it is. Now what about the header behavior on mobile? I had it scrolling away but on smaller screens you lose the nav context pretty fast.\nMaya: I think we should keep it sticky on mobile. The nav is essential and people shouldn't have to scroll all the way back up just to navigate.\nJake: Makes sense. I'll update the branch - I've got everything on feature/redesign-landing.\nMaya: Perfect. Oh, the hero section still needs that parallax animation we talked about last week. I haven't started on that yet.\nJake: Right, that's a big one. Also, I noticed on the staging build that the mobile nav dropdown is overlapping with the hero content. Have you seen that?\nMaya: Ugh, yeah. That's been there since the last merge. We need to fix that before anything else ships, it's pretty broken looking.\nJake: Oh speaking of the nav, we're still waiting on the new logo from the design team right? I can't really finalize the header layout until we have the actual SVG dimensions.\nMaya: Yeah, I pinged Sarah about it yesterday. She said it's still in review but gave no ETA. That's kind of holding up the whole header area.\nJake: Annoying. Well at least we can work around it for the hero animation stuff. Hey did you end up going on that hike last weekend?\nMaya: We did! The trail up Mt. Wilson was gorgeous. Perfect weather for it too.\nJake: Nice, I've been wanting to do that one. My dog would love it. Anyway, let me push these palette changes and you can take a look.\nMaya: Sounds good.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"Landing redesign decisions are locked (Garnet palette, Söhne font, sticky mobile header). Implementation is pending hero animation and a mobile nav bug fix, blocked on the new logo asset.\",\n  \"decisions\": [\n    \"Use Garnet color palette\",\n    \"Use Söhne font\",\n    \"Keep header sticky on mobile\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Implement hero section animation\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Fix mobile nav overlap bug\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Waiting on updated logo SVG from design\"\n  ],\n  \"next_steps\": [\n    \"Implement hero animation\",\n    \"Fix mobile nav overlap once logo arrives\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"design\",\n      \"path\": \"figma://project/landing-v3\",\n      \"description\": \"Figma file\"\n    },\n    {\n      \"type\": \"code\",\n      \"path\": \"feature/redesign-landing\",\n      \"description\": \"Working branch\"\n    }\n  ],\n  \"discarded\": [\n    \"Weekend hiking chat\"\n  ]\n}"}
{"sample_id": "handoff-003", "input": "Session transcript:\n\nDev1: I've been staring at this /memory bug for an hour. Users keep reporting that the memory panel shows old data even after they update blocks.\nDev2: Which component handles the memory display? Is that MemoryViewer?\nDev1: Yeah. I added some logging and I think the problem is it's reading from the agentState cache instead of making a fresh API call.\nDev2: Oh wait, so when you open the panel it just grabs whatever agentState has cached from the last render?\nDev1: Exactly. If you updated memory through the API or through another tab, the MemoryViewer still shows the stale version. It never refetches.\nDev2: That's definitely the bug then. We should just make it fetch fresh memory blocks every time you open the panel.\nDev1: Yeah that's what I'm thinking. The overhead of an extra API call on panel open is negligible compared to the confusion it causes.\nDev2: Agreed, let's go with that. Hey have you seen PR #9240? Tim's logprobs branch is getting huge.\nDev1: I saw the notification, but that's a completely different area from what we're looking at. Let's stay focused here.\nDev2: Right, right. So for the memory fix, we should definitely add a regression test. Like, update memory via the API, reopen the panel, assert it shows the fresh value.\nDev1: Good call. I'll write that up. Oh I already filed MEM-217 for tracking.\nDev2: Nice. Think we can get this into the next patch release? The thread in #support is getting pretty active.\nDev1: Yeah we should aim for that. Let me get the fix done today and the test written, and we can cut the patch by end of week.\nDev2: Sounds like a plan.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"We identified the /memory UI bug as stale agentState caching and decided to fetch fresh blocks on panel open. Fix needs a regression test and a patch release.\",\n  \"decisions\": [\n    \"Fetch fresh memory blocks when MemoryViewer opens\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Add regression test for memory refresh\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Ship fix in next patch release\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [],\n  \"next_steps\": [\n    \"Write regression test\",\n    \"Prepare patch release\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"issue\",\n      \"path\": \"MEM-217\",\n      \"description\": \"Bug ticket\"\n    }\n  ],\n  \"discarded\": [\n    \"Reference to unrelated PR #9240\"\n  ]\n}"}
{"sample_id": "handoff-004", "input": "Session transcript:\n\nPriya: So I've been reading through both SLIME and rLLM for our initial training experiments. I think SLIME is the better starting point.\nKai: Why SLIME over rLLM? I thought rLLM had better documentation.\nPriya: The docs are better, yeah, but SLIME's integration with our existing stack is much smoother. And the benchmarks I found show comparable performance for our scale.\nKai: Fair enough. Let's go with SLIME then and we can always revisit if it doesn't work out.\nPriya: Cool. I started putting together some notes in the planning doc. Let me grab the link... here: https://docs.google.com/document/d/1j38hm-2e0uM00f9LhLcoIp1z4lY8kXMTEIBpew-EQ4s/edit\nKai: Bookmarked. We should flesh that out into a proper training plan though, with data splits, hyperparameters, timeline, all that.\nPriya: Yeah I'll draft up a full plan. The other thing I want to verify is whether SGLang is properly integrated in the letta server. I saw some import references in the codebase but haven't confirmed it works end to end.\nKai: Good point, that's pretty important if we want the inference path to actually function. Can you check that?\nPriya: I was going to, but... so the GCP instance we were using is down.\nKai: Wait seriously? What happened?\nPriya: Something about a billing issue. The billing alert triggered and auto-suspended the instance. I pinged infra about it but they said it might take a day or two to get resolved.\nKai: That's a blocker for basically everything then. We can't run any training or even test SGLang without a GPU instance.\nPriya: Right. I can at least work on the plan doc and do local code review in the meantime.\nKai: True. Oh hey, can you order coffee for the team while you're at it? We're completely out of the dark roast.\nPriya: Haha sure, I'll put in an order this afternoon.\nKai: Thanks. Okay let me know when the GCP situation gets resolved.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"We chose SLIME over rLLM for initial training. Work is blocked by GCP billing; next steps are to draft a training plan and confirm SGLang integration.\",\n  \"decisions\": [\n    \"Use SLIME for initial training experiments\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Draft training plan doc\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Verify SGLang integration in letta server\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"GCP billing issue paused the instance\"\n  ],\n  \"next_steps\": [\n    \"Draft training plan\",\n    \"Check SGLang integration once billing is resolved\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"doc\",\n      \"path\": \"https://docs.google.com/document/d/1j38hm-2e0uM00f9LhLcoIp1z4lY8kXMTEIBpew-EQ4s/edit\",\n      \"description\": \"Main planning doc\"\n    }\n  ],\n  \"discarded\": [\n    \"Coffee order note\"\n  ]\n}"}
{"sample_id": "handoff-005", "input": "Session transcript:\n\nLin: Alright, so we need to figure out the data pipeline architecture. Where are we landing raw logs?\nOmar: I was thinking S3. We already have the acme-logs bucket set up. We could just do s3://acme-logs/raw as the ingestion target.\nLin: That works. And for the processed output format? Last time we used CSV but it was a nightmare once files got over a few gigs.\nOmar: Yeah CSV is out. I'd say parquet - it's columnar, compresses well, and basically everything downstream can query it directly.\nLin: Parquet makes sense. I had a project last year where we tried Avro and it was painful for ad-hoc analytics queries.\nOmar: Ha, yeah parquet is definitely the way to go for our use case. So we'll need an ETL script to handle the raw-to-parquet transformation. I can write that, probably a Python script using pyarrow.\nLin: Cool. And then we need to schedule it. Daily cadence should be fine for now right?\nOmar: Yeah daily. I'll set up a DAG in Airflow for it. Oh wait actually, do we have the AWS credentials set up for the staging environment?\nLin: Hmm, I don't think so. I tried to access the staging bucket last week and got access denied.\nOmar: That's going to be a problem. We can't really test the pipeline end to end without staging access.\nLin: Yeah, I'll file a request with the cloud team today. Hopefully it's just an IAM policy update.\nOmar: In the meantime I updated the pipeline config with the bucket paths and schema definitions. It's at infra/config/pipeline.yaml.\nLin: Nice. Oh by the way, you keep spelling it \"parqet\" in the config comments.\nOmar: Wait do I? Haha, I always mess that up. Is it p-a-r-q-u-e-t?\nLin: Yeah, like the flooring. French word.\nOmar: Right right. Okay I'll fix those comments. Anyway, once we get the AWS creds sorted we should be good to start testing the full pipeline.\nLin: Sounds good. I'll chase down those credentials today.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"We decided on S3 for raw log storage and parquet for processed data. ETL and scheduling are pending, blocked by missing AWS creds.\",\n  \"decisions\": [\n    \"Store raw logs in s3://acme-logs/raw\",\n    \"Use parquet for processed outputs\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Write ETL script to transform raw logs to parquet\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add daily cron in Airflow\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Missing AWS credentials for staging\"\n  ],\n  \"next_steps\": [\n    \"Obtain AWS creds\",\n    \"Implement ETL and Airflow schedule\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"config\",\n      \"path\": \"infra/config/pipeline.yaml\",\n      \"description\": \"Pipeline config\"\n    }\n  ],\n  \"discarded\": [\n    \"Typo discussion about 'parqet'\"\n  ]\n}"}
{"sample_id": "handoff-006", "input": "Session transcript:\n\nNate: Okay so for the session-handoff eval, we need to decide how we're actually grading the outputs. What are you thinking for v0?\nSara: I think we should use a model_judge rubric approach. It's flexible enough that we can iterate on the criteria without having to change any infrastructure.\nNate: Makes sense. Definitely better than trying to write brittle string-matching checks or regex patterns.\nSara: Exactly. One thing I feel strongly about though - the output format needs to be raw JSON only. No markdown code fences, no extra commentary around it.\nNate: Why raw JSON specifically? Just for parsing simplicity?\nSara: Partially, but it also tests whether the model can follow format instructions precisely. If it wraps the JSON in triple backticks or adds \"Here's the output:\" before it, that should count against it.\nNate: Yeah that's actually a good quality signal. Okay so raw JSON, model_judge rubric. I set up the env folder at letta-leaderboard/sidecar-envs/session-handoff/ already by the way.\nSara: Oh nice. So the next thing is we need to actually write the rubric - you know, the text file with the scoring criteria and the breakdown of what earns full marks vs partial.\nNate: I'll take that on. Shouldn't be too hard now that we've agreed on the grading approach. We also need a smoke suite yaml to run quick sanity checks during development.\nSara: True. Maybe like 3-4 samples in the smoke suite, just enough to make sure the pipeline doesn't blow up before we run the full thing.\nNate: Yeah exactly. Hey random question - do you use emojis in your commit messages? I keep going back and forth on whether that's professional.\nSara: Ha, I used to but I stopped. Most linters flag them anyway and it messes up some log parsing tools we use.\nNate: Yeah that's kind of what I figured. Alright, I'll write up the rubric today and get the smoke suite going.\nSara: Sounds like a plan. Let me know if you want me to review the rubric before you merge it.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"We set v0 grading to use model_judge with raw JSON-only outputs. Remaining work is to write the rubric and add a smoke suite.\",\n  \"decisions\": [\n    \"Use model_judge rubric for v0 grading\",\n    \"Require raw JSON only (no code fences)\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Write rubric text file\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add smoke suite YAML\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [],\n  \"next_steps\": [\n    \"Write rubric\",\n    \"Add smoke suite\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"dir\",\n      \"path\": \"letta-leaderboard/sidecar-envs/session-handoff/\",\n      \"description\": \"Env folder\"\n    }\n  ],\n  \"discarded\": [\n    \"Emoji usage chat\"\n  ]\n}"}
{"sample_id": "handoff-007", "input": "Session transcript:\n\nRavi: On-call update — right after the 10:05 deploy of payments-service v1.12.0, p95 latency jumped from ~220ms to ~1.8s.\nMina: Error rates too?\nRavi: Not really, but timeouts are climbing on checkout. It’s starting to impact orders.\nTess: Do we have a quick mitigation?\nMina: We should roll back to v1.11.3 first. If it’s the deploy, we buy time.\nRavi: Agreed. Rolling back now.\n\nMina: I diffed the query plans. The new release added a query on payments where clause (status, created_at) but there’s no composite index. That’s likely the regression.\nRavi: Can we add an index safely?\nMina: Yes, but it should be CREATE INDEX CONCURRENTLY in prod.\nTess: Does that mean we can re-deploy v1.12.0 today?\nMina: Not until the index finishes and we run a quick load test. I also want the new fast-path behind a feature flag.\nRavi: Let’s keep `use_fast_path` default OFF until we validate.\n\nTess: For follow-ups, I want a postmortem doc by end of day.\nRavi: I’ll own the postmortem.\nMina: I’ll open a PR for the index + flag.\nTess: Also: we should add a canary step in CI for payments-service and an alert on p95 > 500ms.\n\nRavi: Random aside, are the tacos still happening for lunch?\nMina: Please, yes.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"A deploy of payments-service v1.12.0 caused a major latency regression impacting checkout. The team rolled back and identified a missing composite index as the likely cause. The fix will be shipped behind a feature flag and only re-enabled after the index build and load testing.\",\n  \"decisions\": [\n    \"Roll back payments-service to v1.11.3 to mitigate latency\",\n    \"Add the required composite index using CREATE INDEX CONCURRENTLY\",\n    \"Keep feature flag `use_fast_path` OFF until the fix is validated\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Open PR to add composite index + feature flag gating\",\n      \"owner\": \"Mina\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Write and publish postmortem\",\n      \"owner\": \"Ravi\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add CI canary step and p95 latency alert\",\n      \"owner\": \"Tess\",\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Index build needs to run safely in production (requires careful timing/monitoring)\"\n  ],\n  \"next_steps\": [\n    \"Complete rollback verification and monitor checkout\",\n    \"Build the index concurrently and run a quick load test\",\n    \"Draft postmortem and schedule follow-up\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"service\",\n      \"path\": \"services/payments-service/\",\n      \"description\": \"Payments service codebase\"\n    },\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/postmortems/2026-02-04-payments-latency.md\",\n      \"description\": \"Postmortem write-up\"\n    },\n    {\n      \"type\": \"flag\",\n      \"path\": \"use_fast_path\",\n      \"description\": \"Feature flag to gate the fast-path\"\n    }\n  ],\n  \"discarded\": [\n    \"Lunch tacos chat\"\n  ]\n}"}
{"sample_id": "handoff-008", "input": "Session transcript:\n\nElena: For Docs Search, we need to pick an approach. Embeddings would be nice, but we’re trying to ship something in 2 weeks.\nNoah: Agree. For v1, I vote Postgres full-text search: tsvector + GIN. It’s boring but reliable.\nMaya: From a UX perspective, users mostly want keyword search + filters. Semantic can come later.\nElena: Okay, so decision: v1 is keyword search only.\n\nNoah: API shape: GET /v1/docs/search?q=...&cursor=...&limit=...\nMaya: Cursor pagination is better than offset, right?\nNoah: Yes, avoids duplicates when docs are updated.\nElena: Let’s do cursor.\n\nMaya: Any legal/privacy concerns with indexing customer content?\nElena: We need security review, but we can scope it: only index within a workspace, and respect document ACLs.\nNoah: I’ll draft an RFC. Also need a migration to add the tsvector column + GIN index.\nElena: And update OpenAPI + docs page.\n\nMaya: Totally unrelated — did you see the new office chairs arrived?\nNoah: I’m jealous, ours are ancient.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team planned the initial Docs Search feature and chose a fast, reliable implementation path to meet a two-week deadline. They decided to ship v1 as Postgres full-text keyword search with cursor pagination, deferring semantic/embedding search. Follow-ups include drafting an RFC, adding migrations/indexes, and updating API documentation while ensuring workspace ACLs are respected.\",\n  \"decisions\": [\n    \"Ship Docs Search v1 using Postgres full-text search (tsvector + GIN)\",\n    \"Use cursor-based pagination instead of offset pagination\",\n    \"Defer semantic/embedding search to a later version\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Draft Docs Search RFC (scope, ACLs, API shape)\",\n      \"owner\": \"Noah\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Implement migration for tsvector column and GIN index\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update OpenAPI + docs page for /v1/docs/search\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Security/privacy review for indexing customer document content\"\n  ],\n  \"next_steps\": [\n    \"Write the RFC and get security sign-off\",\n    \"Add DB migration/indexes and wire up API endpoint\",\n    \"Update docs and ship v1\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/rfcs/2026-02-docs-search-v1.md\",\n      \"description\": \"Docs Search RFC\"\n    },\n    {\n      \"type\": \"spec\",\n      \"path\": \"backend/api/openapi.yaml\",\n      \"description\": \"OpenAPI spec\"\n    }\n  ],\n  \"discarded\": [\n    \"Office chair discussion\"\n  ]\n}"}
{"sample_id": "handoff-009", "input": "Session transcript:\n\nLin: We need a plan for event ingestion. Right now we’re dumping JSON to a single bucket and it’s chaos.\nOmar: Let’s standardize. Raw events to GCS, partitioned by date: gs://analytics-raw/events/YYYY/MM/DD/.\nLin: Works. And then curated tables in BigQuery?\nOmar: Yes. We can land raw to GCS, load to a staging table, then use dbt for transforms into final marts.\nLin: I like dbt for the transforms.\n\nOmar: For orchestration, do we stick with Airflow?\nLin: For now yes. One DAG: ingest → load → dbt run → data quality checks.\nOmar: Data quality checks should include: schema drift detection, null rate thresholds, and duplicate event_id checks.\n\nLin: Blocker: I don’t have permissions to create the service account keys in the new GCP project.\nOmar: I’ll file an IAM request.\nLin: Also, we should backfill the last 7 days once the pipeline works.\n\nOmar: Side note, who’s going to the conference next month?\nLin: Still deciding.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team agreed on a cleaner event ingestion architecture: store partitioned raw events in GCS, load into BigQuery staging, and use dbt to transform into curated marts. Airflow will orchestrate the pipeline end-to-end, including data quality checks. Remaining work includes IAM setup, implementing the DAG and dbt models, and running a backfill once the pipeline is stable.\",\n  \"decisions\": [\n    \"Store raw events in GCS partitioned by date under gs://analytics-raw/events/YYYY/MM/DD/\",\n    \"Use BigQuery for staging/curated tables\",\n    \"Use dbt for transformations and Airflow for orchestration\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Create Airflow DAG for ingest → load → dbt → quality checks\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Implement dbt models for curated marts\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Backfill last 7 days after pipeline is stable\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"File IAM request for required service account permissions\",\n      \"owner\": \"Omar\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Missing permissions to create service account keys in the new GCP project\"\n  ],\n  \"next_steps\": [\n    \"Submit and approve IAM request\",\n    \"Build the Airflow DAG and dbt transforms\",\n    \"Run backfill and validate data quality\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"bucket\",\n      \"path\": \"gs://analytics-raw/events/\",\n      \"description\": \"Raw event storage\"\n    },\n    {\n      \"type\": \"tool\",\n      \"path\": \"dbt\",\n      \"description\": \"Transform layer\"\n    }\n  ],\n  \"discarded\": [\n    \"Conference travel chat\"\n  ]\n}"}
{"sample_id": "handoff-010", "input": "Session transcript:\n\nSam: For the mobile app, we need to cut 1.4.0 this week.\nInez: Scope is creeping. Can we freeze features and just stabilize?\nSam: Yes. Let’s branch release/1.4.0 off main tonight.\n\nInez: There’s still that crash on the Settings screen on Android 13.\nSam: I saw it in Sentry but the stack trace isn’t symbolicated yet.\nInez: We need the symbolicated trace to know what line is crashing.\nSam: I’ll get symbols uploaded and wait for Sentry to reprocess.\n\nInez: Also, the Smart Reply experiment is half-baked.\nSam: We should disable `smart_reply_enabled` for the release.\nInez: Agree.\n\nSam: After the crash fix, we update the changelog and ship to TestFlight.\nInez: And run the smoke test suite on both platforms.\n\nSam: Random — anyone watching the game tonight?\nInez: Not if I’m fixing this crash.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team planned the 1.4.0 mobile release and agreed to freeze scope to focus on stability. They will cut a release branch, disable the unfinished Smart Reply feature via a flag, and prioritize fixing an Android 13 Settings crash. The crash investigation is currently blocked on getting a symbolicated Sentry stack trace.\",\n  \"decisions\": [\n    \"Cut release branch release/1.4.0 from main\",\n    \"Disable Smart Reply experiment for the release via `smart_reply_enabled`\",\n    \"Run smoke tests on both platforms before submitting to TestFlight\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Upload symbols and obtain symbolicated Sentry stack trace\",\n      \"owner\": \"Sam\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Fix Android 13 Settings crash\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update changelog/release notes for 1.4.0\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Submit build to TestFlight after validation\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Sentry stack trace is not symbolicated yet for the Android 13 crash\"\n  ],\n  \"next_steps\": [\n    \"Create release/1.4.0 branch and freeze scope\",\n    \"Get symbolicated crash details and implement fix\",\n    \"Run smoke tests and submit to TestFlight\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"branch\",\n      \"path\": \"release/1.4.0\",\n      \"description\": \"Release branch\"\n    },\n    {\n      \"type\": \"flag\",\n      \"path\": \"smart_reply_enabled\",\n      \"description\": \"Feature flag for Smart Reply\"\n    },\n    {\n      \"type\": \"file\",\n      \"path\": \"apps/mobile/CHANGELOG.md\",\n      \"description\": \"Release notes\"\n    }\n  ],\n  \"discarded\": [\n    \"Game-watching small talk\"\n  ]\n}"}
{"sample_id": "handoff-011", "input": "Session transcript:\n\nPriya: Airflow is getting painful for new pipelines. Can we try Dagster?\nJules: I’m open to it, but I don’t want a rewrite of everything.\nPriya: Agreed — keep existing DAGs in Airflow. Let’s pilot Dagster only for the new billing-etl pipeline.\n\nJules: Dagster Cloud or OSS?\nPriya: Procurement for Cloud will take weeks. Start with OSS locally so we can learn.\nJules: Okay.\n\nPriya: We should write down success criteria: dev velocity, observability, on-call burden.\nJules: And a migration plan if we decide to move more later.\nPriya: I’ll draft a short decision doc.\n\nJules: Side note, I got a new espresso grinder and I’m obsessed.\nPriya: Please do not start another coffee hobby in this team.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team discussed workflow pain with Airflow and agreed to trial Dagster without committing to a full migration. They will keep existing pipelines in Airflow and pilot Dagster only for the new billing-etl pipeline, starting with Dagster OSS due to procurement delays for Cloud. Next steps include drafting a decision document and defining success criteria for the pilot.\",\n  \"decisions\": [\n    \"Keep existing pipelines in Airflow (no rewrite)\",\n    \"Pilot Dagster only for the new billing-etl pipeline\",\n    \"Start with Dagster OSS locally rather than Dagster Cloud\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Draft decision doc for Dagster pilot (scope + rationale)\",\n      \"owner\": \"Priya\",\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Define success criteria and evaluation metrics for the pilot\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Create initial Dagster project scaffolding for billing-etl\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Dagster Cloud procurement will take weeks, so Cloud evaluation is delayed\"\n  ],\n  \"next_steps\": [\n    \"Stand up a Dagster OSS proof-of-concept for billing-etl\",\n    \"Define success metrics and review after initial implementation\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/decisions/dagster-pilot.md\",\n      \"description\": \"Decision record for Dagster pilot\"\n    }\n  ],\n  \"discarded\": [\n    \"Coffee grinder discussion\"\n  ]\n}"}
{"sample_id": "handoff-012", "input": "Session transcript:\n\nAvery: For SSO, we’re going with OIDC. IT wants Okta.\nDevon: Fine. For the SPA client, we must use PKCE.\nAvery: Yep.\n\nDevon: Token validation requirements: verify issuer, audience, and nonce on the ID token. Also cache JWKS but respect key rotation.\nAvery: Agreed.\n\nAvery: Cookies — I want SameSite=Lax and HttpOnly for the session cookie.\nDevon: Works.\n\nAvery: Blocker: IT hasn’t provisioned the Okta sandbox app yet.\nDevon: We can stub locally but can’t do end-to-end auth flows without that.\n\nAvery: I’ll write a quick threat model doc. Devon, can you start the validator module?\nDevon: Yes.\n\nAvery: Also unrelated, we should design new laptop stickers.\nDevon: Please no.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team aligned on implementing SSO using OIDC with Okta. Key technical requirements include enforcing PKCE for the SPA, validating ID tokens (iss/aud/nonce) with JWKS caching and rotation handling, and using secure session cookie settings. Work is blocked on IT provisioning an Okta sandbox app for end-to-end testing.\",\n  \"decisions\": [\n    \"Use OIDC with Okta for SSO\",\n    \"Enforce PKCE for the SPA client\",\n    \"Implement strict ID token validation (iss/aud/nonce) with JWKS caching\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Draft threat model for SSO/OIDC rollout\",\n      \"owner\": \"Avery\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Implement OIDC token validator module\",\n      \"owner\": \"Devon\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add integration tests for common OIDC failure modes\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Waiting on IT to provision the Okta sandbox application\"\n  ],\n  \"next_steps\": [\n    \"Get Okta sandbox app created\",\n    \"Implement validator + tests and run end-to-end auth flow\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/security/sso-oidc.md\",\n      \"description\": \"SSO/OIDC implementation notes\"\n    },\n    {\n      \"type\": \"module\",\n      \"path\": \"backend/auth/oidc.py\",\n      \"description\": \"OIDC token validation module\"\n    }\n  ],\n  \"discarded\": [\n    \"Laptop sticker discussion\"\n  ]\n}"}
{"sample_id": "handoff-013", "input": "Session transcript:\n\nMaya: User research takeaway: onboarding is too long. People drop on step 4.\nJon: How many steps do we want?\nMaya: Three max.\n\nJon: What about the survey question set?\nMaya: Move it out of onboarding. Prompt after they create their first project.\nJon: Sounds good.\n\nMaya: Also, “Workspace” is confusing language. Users think it means a folder.\nJon: Rename to “Project” in the UI.\nMaya: Yes.\n\nJon: Analytics: we should add an event when onboarding is complete with the number of steps.\nMaya: Good idea.\n\nJon: Totally unrelated, I’m going to spam you with dog photos later.\nMaya: Please do.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"Based on user research, the team decided to simplify onboarding and improve terminology. Onboarding will be reduced to three steps, the survey will be moved to after first project creation, and the UI term “Workspace” will be renamed to “Project”. They also plan to add an analytics event for onboarding completion.\",\n  \"decisions\": [\n    \"Reduce onboarding flow to three steps\",\n    \"Move the survey to after first project creation\",\n    \"Rename “Workspace” to “Project” in the UI\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Update onboarding flow implementation to 3 steps\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Move survey prompt to post-project-creation flow\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Rename Workspace → Project across UI copy\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add onboarding_completed analytics event (include step_count)\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [],\n  \"next_steps\": [\n    \"Implement onboarding flow changes and copy updates\",\n    \"Add analytics instrumentation and validate event payloads\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"file\",\n      \"path\": \"frontend/src/routes/Onboarding.tsx\",\n      \"description\": \"Onboarding flow\"\n    },\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/analytics/events.md\",\n      \"description\": \"Analytics event definitions\"\n    }\n  ],\n  \"discarded\": [\n    \"Dog photo chat\"\n  ]\n}"}
{"sample_id": "handoff-014", "input": "Session transcript:\n\nKen: Our AWS bill is up 30% MoM. We need quick wins.\nSasha: Compute first. We can move API nodes from m5.large to m6i.large — better price/perf.\nKen: Any risk?\nSasha: Low. We should benchmark but it’s straightforward.\n\nKen: Autoscaling?\nSasha: Right now min=1, max=6. I want min=2 for redundancy and max=10 for spikes.\nKen: Okay.\n\nSasha: Logs: we’re shipping uncompressed JSON to S3. Enable gzip compression before upload.\nKen: And retention?\nSasha: Keep 14 days hot, archive older.\n\nKen: Blocker: reserved instances would help a lot but finance approval is needed.\nSasha: I’ll send the request.\n\nKen: Totally unrelated, is KubeCon worth going to?\nSasha: Only if you like standing in lines.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team reviewed cost increases and agreed on several optimizations across compute, autoscaling, and log storage. They will switch API instances to m6i.large, adjust autoscaling bounds for redundancy and peak handling, and compress logs before sending to S3 while reducing hot retention to 14 days. Purchasing reserved instances is blocked on finance approval.\",\n  \"decisions\": [\n    \"Switch API instances from m5.large to m6i.large\",\n    \"Set autoscaling min=2 and max=10\",\n    \"Enable gzip compression for logs and reduce hot retention to 14 days\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Benchmark m6i.large vs m5.large for API workloads\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update Terraform for instance type and autoscaling bounds\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Implement log gzip compression and adjust retention policies\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Request finance approval for reserved instances\",\n      \"owner\": \"Sasha\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Finance approval required to purchase reserved instances\"\n  ],\n  \"next_steps\": [\n    \"Run benchmarks and update Terraform\",\n    \"Enable log compression/retention changes\",\n    \"Submit RI purchase request\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"file\",\n      \"path\": \"infra/terraform/prod/compute.tf\",\n      \"description\": \"Compute configuration\"\n    },\n    {\n      \"type\": \"file\",\n      \"path\": \"infra/terraform/prod/autoscaling.tf\",\n      \"description\": \"Autoscaling configuration\"\n    }\n  ],\n  \"discarded\": [\n    \"KubeCon discussion\"\n  ]\n}"}
{"sample_id": "handoff-015", "input": "Session transcript:\n\nDina: Customer escalation: exports time out for large workspaces, and they need CSV.\nMarco: Today it’s JSON-only and synchronous. That’s why it times out.\nDina: We should add async export jobs.\nMarco: Agree. We can return a job_id and let them poll.\n\nDina: Also, they complained the timestamps are in local time and inconsistent.\nMarco: Let’s default to UTC but allow tz=America/New_York style overrides.\n\nDina: Rate limiting? The customer hammered it and melted their own worker queue.\nMarco: We should rate limit exports per workspace.\n\nDina: Blocker: we can’t access their dataset due to the DPA.\nMarco: We’ll need an anonymized reproduction dataset from them.\n\nDina: Also, I swear spreadsheets are ruining my life.\nMarco: Same.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"A customer escalation revealed that large exports are timing out and CSV output is needed. The team decided to move exports to an async job model, default timestamps to UTC while allowing an explicit timezone parameter, and add per-workspace rate limiting to protect the system. Investigation is blocked by lack of access to the customer’s dataset due to privacy constraints.\",\n  \"decisions\": [\n    \"Implement exports as asynchronous jobs returning a job_id\",\n    \"Add CSV export output option\",\n    \"Default export timestamps to UTC while allowing a tz=... override\",\n    \"Add per-workspace export rate limiting\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Request anonymized reproduction dataset from customer\",\n      \"owner\": \"Dina\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Implement async export job flow (job_id + polling)\",\n      \"owner\": null,\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Add CSV serializer and integration tests\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update support docs and response template for exports\",\n      \"owner\": null,\n      \"priority\": \"low\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [\n    \"Cannot access the customer’s dataset due to DPA/privacy restrictions\"\n  ],\n  \"next_steps\": [\n    \"Obtain anonymized data for reproduction\",\n    \"Build async export + CSV support and add tests\",\n    \"Update documentation and support messaging\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"ticket\",\n      \"path\": \"SUP-1842\",\n      \"description\": \"Customer export escalation\"\n    },\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/support/data-export.md\",\n      \"description\": \"Data export documentation\"\n    },\n    {\n      \"type\": \"code\",\n      \"path\": \"backend/routes/export.py\",\n      \"description\": \"Export endpoint implementation\"\n    }\n  ],\n  \"discarded\": [\n    \"Complaints about spreadsheets\"\n  ]\n}"}
{"sample_id": "handoff-016", "input": "Session transcript:\n\nNina: Hiring retro: feedback is inconsistent and slow.\nOwen: People don’t know what “good” looks like. We need a standardized rubric.\nNina: Let’s do a 1-4 scale across: problem solving, communication, code quality, and role fit.\nOwen: And require written rationale for each score.\n\nNina: Also, we should offer a take-home alternative for folks who need accommodations, but keep the default as the live exercise.\nOwen: Agree.\n\nNina: Another pain point: feedback arrives days later.\nOwen: Require feedback within 24 hours.\n\nNina: Action items: update the question bank, update the Greenhouse scorecard templates, and schedule an interviewer calibration session.\nOwen: I can lead the calibration.\n\nNina: Unrelated — the office plants keep dying.\nOwen: Maybe we need a plant rubric too.\n\nOutput `handoff.json` as a single JSON object only (no code fences) with keys:\nsummary, decisions, open_todos, blockers, next_steps, artifacts, discarded.", "ground_truth": "{\n  \"summary\": \"The team agreed to improve hiring consistency by standardizing evaluation and tightening feedback timelines. They decided to create a structured rubric with scored categories and written rationale, provide a take-home alternative for accommodations, and require interview feedback within 24 hours. Next steps include updating the question bank, scorecard templates, and running an interviewer calibration session.\",\n  \"decisions\": [\n    \"Adopt a standardized interview rubric with scored categories and written rationale\",\n    \"Offer a take-home alternative for accommodations while keeping the live exercise as default\",\n    \"Require interviewer feedback within 24 hours\"\n  ],\n  \"open_todos\": [\n    {\n      \"task\": \"Create and publish interview rubric doc\",\n      \"owner\": \"Nina\",\n      \"priority\": \"high\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update question bank for interviews\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Update Greenhouse scorecard templates to match rubric\",\n      \"owner\": null,\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    },\n    {\n      \"task\": \"Schedule and run interviewer calibration session\",\n      \"owner\": \"Owen\",\n      \"priority\": \"med\",\n      \"status\": \"open\"\n    }\n  ],\n  \"blockers\": [],\n  \"next_steps\": [\n    \"Draft rubric and update hiring materials\",\n    \"Run calibration session and enforce 24-hour feedback rule\"\n  ],\n  \"artifacts\": [\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/hiring/interview-rubric.md\",\n      \"description\": \"Interview evaluation rubric\"\n    },\n    {\n      \"type\": \"doc\",\n      \"path\": \"docs/hiring/question-bank.md\",\n      \"description\": \"Interview question bank\"\n    }\n  ],\n  \"discarded\": [\n    \"Office plant discussion\"\n  ]\n}"}
